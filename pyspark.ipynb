{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMg3MkQJ2pAzcwvgyS/R9i1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xaknight/data-science-engineering/blob/main/pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import psutil\n",
        "\n",
        "# Function to get CPU information\n",
        "def get_cpu_info():\n",
        "    cpu_count = os.cpu_count()\n",
        "    print(f\"Number of CPUs: {cpu_count}\")\n",
        "\n",
        "# Function to get RAM information\n",
        "def get_ram_info():\n",
        "    ram = psutil.virtual_memory()\n",
        "    total_ram = ram.total / (1024 ** 3)  # Convert bytes to GB\n",
        "    available_ram = ram.available / (1024 ** 3)  # Convert bytes to GB\n",
        "    print(f\"Total RAM: {total_ram:.2f} GB\")\n",
        "    print(f\"Available RAM: {available_ram:.2f} GB\")\n",
        "\n",
        "# Function to get disk information\n",
        "def get_disk_info():\n",
        "    disk = psutil.disk_usage('/')\n",
        "    total_disk = disk.total / (1024 ** 3)  # Convert bytes to GB\n",
        "    free_disk = disk.free / (1024 ** 3)  # Convert bytes to GB\n",
        "    print(f\"Total Disk Space: {total_disk:.2f} GB\")\n",
        "    print(f\"Free Disk Space: {free_disk:.2f} GB\")\n",
        "\n",
        "# Run the functions\n",
        "print(\"System Information in Google Colab:\")\n",
        "print(\"----------------------------------\")\n",
        "get_cpu_info()\n",
        "get_ram_info()\n",
        "get_disk_info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpTgNBBZsx1G",
        "outputId": "8325e22a-c850-4853-cbcc-7385dbab6e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System Information in Google Colab:\n",
            "----------------------------------\n",
            "Number of CPUs: 2\n",
            "Total RAM: 12.67 GB\n",
            "Available RAM: 10.96 GB\n",
            "Total Disk Space: 107.72 GB\n",
            "Free Disk Space: 72.69 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYMMPXlBr9fD",
        "outputId": "8788417a-72c3-4986-9464-7d74c0bfb98c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"EcommerceAnalysis\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "2z_rkrEbsArr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rand, expr, col\n",
        "import random\n",
        "\n",
        "# Generate synthetic data\n",
        "data = spark.range(100000).select(\n",
        "    expr(\"id as transaction_id\"),\n",
        "    (rand() * 10000).cast(\"int\").alias(\"customer_id\"),\n",
        "    expr(\"array('Electronics', 'Clothing', 'Books', 'Home')[int(rand() * 4)]\").alias(\"category\"),\n",
        "    (rand() * 1000).cast(\"float\").alias(\"amount\"),\n",
        "    expr(\"array('Mumbai', 'Delhi', 'Bangalore', 'Pune')[int(rand() * 4)]\").alias(\"region\"),\n",
        "    (rand() * 0.2 - 0.1).alias(\"discount\"),  # Some negative, some positive\n",
        "    expr(\"if(rand() > 0.9, null, amount * (1 - discount))\").alias(\"final_amount\")  # 10% nulls\n",
        ")\n",
        "\n",
        "# Add duplicates and outliers for realism\n",
        "data_with_noise = data.union(data.sample(0.05))  # 5% duplicates\n",
        "data_with_noise.write.mode(\"overwrite\").parquet(\"transactions.parquet\")  # Save to disk\n",
        "df = spark.read.parquet(\"transactions.parquet\")\n",
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jPm076asHQj",
        "outputId": "374c1b5a-8025-42c9-b105-5d1d9d716b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+-----------+---------+---------+--------------------+------------------+\n",
            "|transaction_id|customer_id|   category|   amount|   region|            discount|      final_amount|\n",
            "+--------------+-----------+-----------+---------+---------+--------------------+------------------+\n",
            "|         50000|       1644|Electronics| 736.2237|Bangalore|0.018013626419986495|  722.961635265142|\n",
            "|         50001|       5195|      Books| 593.2392|    Delhi|-0.04274419532888...| 618.5967288811426|\n",
            "|         50002|       4625|Electronics| 282.7866|     Pune| 0.01714273140612163| 277.9388560086717|\n",
            "|         50003|       6943|       Home|216.02968|     Pune|-0.03806353523521...| 224.2525316182528|\n",
            "|         50004|       2896|      Books|273.79163|    Delhi| 0.06022357157652536| 257.3029163925097|\n",
            "|         50005|       6640|      Books|827.41724|   Mumbai|-0.05611531561395...| 873.8480156891038|\n",
            "|         50006|       1132|Electronics|  592.954|Bangalore|-0.04745861913578...| 621.0947565699543|\n",
            "|         50007|       2545|       Home| 870.6697|Bangalore|-0.01611010731002...|              NULL|\n",
            "|         50008|       4799|Electronics|502.08908|     Pune|0.010288938731170136|496.92311702049767|\n",
            "|         50009|       9516|      Books|200.94675|Bangalore|0.052953548805254685|  190.305903460855|\n",
            "+--------------+-----------+-----------+---------+---------+--------------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, mean, col\n",
        "\n",
        "# Remove duplicates\n",
        "df_cleaned = df.dropDuplicates([\"transaction_id\", \"customer_id\", \"amount\"])\n",
        "\n",
        "# Fill null final_amount with mean per category\n",
        "mean_final = df_cleaned.groupBy(\"category\").agg(mean(\"final_amount\").alias(\"mean_final\"))\n",
        "df_filled = df_cleaned.join(mean_final, \"category\", \"left\") \\\n",
        "    .withColumn(\"final_amount\", when(col(\"final_amount\").isNull(), col(\"mean_final\")).otherwise(col(\"final_amount\"))) \\\n",
        "    .drop(\"mean_final\")\n",
        "\n",
        "# Filter outliers (amount > 5000)\n",
        "df_final = df_filled.filter(col(\"amount\") <= 5000)\n",
        "df_final.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYMCxLjJtAl4",
        "outputId": "2c19d132-8515-4c7d-a114-81d2de4a5c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+-----------+---------+---------+--------------------+------------------+\n",
            "|   category|transaction_id|customer_id|   amount|   region|            discount|      final_amount|\n",
            "+-----------+--------------+-----------+---------+---------+--------------------+------------------+\n",
            "|       Home|             0|       7753|171.48724|     Pune|-0.08708886050721805|186.42187229355002|\n",
            "|Electronics|             1|       9949|21.219477|Bangalore|0.043336644906418226| 20.29989577298859|\n",
            "|      Books|             2|       5540| 577.2987|   Mumbai|-0.08881754852713303| 628.5729618943508|\n",
            "|      Books|             4|        959|168.20488|Bangalore| 0.03364352494906048|162.54587469195792|\n",
            "|      Books|             5|       5299|188.01472|     Pune| 0.07088463180508173|  174.687370194923|\n",
            "|Electronics|             7|       9196|  976.126|Bangalore|-0.02119646003401...| 996.8163918128753|\n",
            "|Electronics|            11|       6951| 700.7263|   Mumbai|0.012337023976774095| 692.0814409686188|\n",
            "|   Clothing|            12|       5643|916.67566|     Pune| 0.08931167603859669| 834.8058196745642|\n",
            "|      Books|            15|       7589| 65.96385|    Delhi|-0.01834415951717...| 67.17390335085828|\n",
            "|Electronics|            18|        625| 700.8979|     Pune|-0.09773323898736129| 769.3989089951777|\n",
            "+-----------+--------------+-----------+---------+---------+--------------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate sales\n",
        "sales_trends = df_final.groupBy(\"region\", \"category\").agg(\n",
        "    {\"final_amount\": \"sum\", \"transaction_id\": \"count\"}\n",
        ").withColumnRenamed(\"sum(final_amount)\", \"total_sales\") \\\n",
        " .withColumnRenamed(\"count(transaction_id)\", \"transaction_count\")\n",
        "\n",
        "sales_trends.orderBy(\"region\", \"total_sales\", ascending=False).show()\n",
        "\n",
        "# Use Spark SQL for a different view\n",
        "df_final.createOrReplaceTempView(\"transactions\")\n",
        "spark.sql(\"\"\"\n",
        "    SELECT region, category, ROUND(SUM(final_amount), 2) as total_sales\n",
        "    FROM transactions\n",
        "    GROUP BY region, category\n",
        "    ORDER BY total_sales DESC\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQAb22E2vrAn",
        "outputId": "3f112f6e-0305-4362-e315-2d69e265dec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+-----------------+------------------+\n",
            "|   region|   category|transaction_count|       total_sales|\n",
            "+---------+-----------+-----------------+------------------+\n",
            "|     Pune|   Clothing|             6320|  3173964.68105173|\n",
            "|     Pune|Electronics|             6344| 3169371.548943664|\n",
            "|     Pune|       Home|             6209|3112125.2852559783|\n",
            "|     Pune|      Books|             6256|3102030.5211500167|\n",
            "|   Mumbai|Electronics|             6321|3187738.4410494855|\n",
            "|   Mumbai|   Clothing|             6303|3162128.4813304814|\n",
            "|   Mumbai|       Home|             6150| 3095768.244115215|\n",
            "|   Mumbai|      Books|             6214|  3090104.10231376|\n",
            "|    Delhi|      Books|             6339|3178326.9381144457|\n",
            "|    Delhi|Electronics|             6362|3156056.6066346867|\n",
            "|    Delhi|       Home|             6243| 3108341.318252579|\n",
            "|    Delhi|   Clothing|             6195| 3081282.144769721|\n",
            "|Bangalore|      Books|             6292|3148400.6215088554|\n",
            "|Bangalore|   Clothing|             6187|3088752.0011445163|\n",
            "|Bangalore|       Home|             6121|3072918.1943757785|\n",
            "|Bangalore|Electronics|             6144|3038340.6321426425|\n",
            "+---------+-----------+-----------------+------------------+\n",
            "\n",
            "+---------+-----------+-----------+\n",
            "|   region|   category|total_sales|\n",
            "+---------+-----------+-----------+\n",
            "|   Mumbai|Electronics| 3187738.44|\n",
            "|    Delhi|      Books| 3178326.94|\n",
            "|     Pune|   Clothing| 3173964.68|\n",
            "|     Pune|Electronics| 3169371.55|\n",
            "|   Mumbai|   Clothing| 3162128.48|\n",
            "|    Delhi|Electronics| 3156056.61|\n",
            "|Bangalore|      Books| 3148400.62|\n",
            "|     Pune|       Home| 3112125.29|\n",
            "|    Delhi|       Home| 3108341.32|\n",
            "|     Pune|      Books| 3102030.52|\n",
            "|   Mumbai|       Home| 3095768.24|\n",
            "|   Mumbai|      Books|  3090104.1|\n",
            "|Bangalore|   Clothing|  3088752.0|\n",
            "|    Delhi|   Clothing| 3081282.14|\n",
            "|Bangalore|       Home| 3072918.19|\n",
            "|Bangalore|Electronics| 3038340.63|\n",
            "+---------+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank, sum as sum_\n",
        "\n",
        "# Window spec for ranking\n",
        "windowSpec = Window.partitionBy(\"region\").orderBy(col(\"total_spent\").desc())\n",
        "\n",
        "# Calculate total spending per customer\n",
        "customer_spending = df_final.groupBy(\"region\", \"customer_id\").agg(sum_(\"final_amount\").alias(\"total_spent\"))\n",
        "\n",
        "# Rank customers\n",
        "top_customers = customer_spending.withColumn(\"rank\", rank().over(windowSpec)) \\\n",
        "    .filter(col(\"rank\") <= 5) \\\n",
        "    .orderBy(\"region\", \"rank\")\n",
        "\n",
        "top_customers.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5c6bB5ZxK7J",
        "outputId": "629541d9-ea5f-405e-d733-a93787dd0ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+------------------+----+\n",
            "|   region|customer_id|       total_spent|rank|\n",
            "+---------+-----------+------------------+----+\n",
            "|Bangalore|       5839| 5685.310971342755|   1|\n",
            "|Bangalore|       8733| 5322.331025792927|   2|\n",
            "|Bangalore|        311| 5299.272872508585|   3|\n",
            "|Bangalore|       5288| 5231.011926201888|   4|\n",
            "|Bangalore|       8565|5138.0618893409755|   5|\n",
            "|    Delhi|       3684| 5551.204706996249|   1|\n",
            "|    Delhi|       2862|5479.2944667859865|   2|\n",
            "|    Delhi|       2427| 5389.773814958524|   3|\n",
            "|    Delhi|       1513| 5344.972533386377|   4|\n",
            "|    Delhi|       7005| 5344.279685344902|   5|\n",
            "|   Mumbai|       6174| 6719.172965303682|   1|\n",
            "|   Mumbai|       1077| 5746.126345760734|   2|\n",
            "|   Mumbai|       4216| 5366.283952614199|   3|\n",
            "|   Mumbai|       6484| 5341.762108601681|   4|\n",
            "|   Mumbai|       1433|5276.4591886204125|   5|\n",
            "|     Pune|       2459| 5886.707844481927|   1|\n",
            "|     Pune|       3990| 5819.454588338279|   2|\n",
            "|     Pune|       8982| 5584.890313982952|   3|\n",
            "|     Pune|       3945| 5243.229620329511|   4|\n",
            "|     Pune|        842| 5158.479450856062|   5|\n",
            "+---------+-----------+------------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a fake timestamp column\n",
        "from pyspark.sql.functions import floor, current_timestamp\n",
        "df_with_time = df_final.withColumn(\"batch_id\", floor(rand() * 5))  # 5 batches\n",
        "\n",
        "# Process each batch\n",
        "for batch in range(5):\n",
        "    batch_data = df_with_time.filter(col(\"batch_id\") == batch)\n",
        "    print(f\"Processing Batch {batch}:\")\n",
        "    batch_data.groupBy(\"region\").agg({\"final_amount\": \"sum\"}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k06j8M7x0-t",
        "outputId": "de8fe1a1-53bb-46ac-9ecd-9ece6650134e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Batch 0:\n",
            "+---------+------------------+\n",
            "|   region| sum(final_amount)|\n",
            "+---------+------------------+\n",
            "|Bangalore| 2454550.812971227|\n",
            "|   Mumbai|2498190.9703327343|\n",
            "|     Pune| 2501915.098417806|\n",
            "|    Delhi| 2533161.533821532|\n",
            "+---------+------------------+\n",
            "\n",
            "Processing Batch 1:\n",
            "+---------+------------------+\n",
            "|   region| sum(final_amount)|\n",
            "+---------+------------------+\n",
            "|Bangalore| 2424294.401773586|\n",
            "|   Mumbai| 2529680.653171329|\n",
            "|     Pune|2508099.3846215564|\n",
            "|    Delhi| 2493725.149581561|\n",
            "+---------+------------------+\n",
            "\n",
            "Processing Batch 2:\n",
            "+---------+------------------+\n",
            "|   region| sum(final_amount)|\n",
            "+---------+------------------+\n",
            "|Bangalore|2486755.5404315954|\n",
            "|   Mumbai| 2524343.406739462|\n",
            "|     Pune|2455642.9802046944|\n",
            "|    Delhi|2496585.9586052266|\n",
            "+---------+------------------+\n",
            "\n",
            "Processing Batch 3:\n",
            "+---------+------------------+\n",
            "|   region| sum(final_amount)|\n",
            "+---------+------------------+\n",
            "|Bangalore|2504070.8089441517|\n",
            "|   Mumbai|2507069.3094978277|\n",
            "|     Pune| 2497822.699265678|\n",
            "|    Delhi| 2467596.929502614|\n",
            "+---------+------------------+\n",
            "\n",
            "Processing Batch 4:\n",
            "+---------+-----------------+\n",
            "|   region|sum(final_amount)|\n",
            "+---------+-----------------+\n",
            "|Bangalore|2478739.885051243|\n",
            "|   Mumbai|2476454.929067605|\n",
            "|     Pune|2594011.873891657|\n",
            "|    Delhi|2532937.436260498|\n",
            "+---------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save as CSV (Colab will store in /content/)\n",
        "sales_trends.write.mode(\"overwrite\").csv(\"sales_trends.csv\")\n",
        "top_customers.write.mode(\"overwrite\").csv(\"top_customers.csv\")\n",
        "\n",
        "# Download from Colab\n",
        "from google.colab import files\n",
        "import glob\n",
        "\n",
        "# Download sales_trends\n",
        "for file_path in glob.glob(\"sales_trends.csv/part-00000-*.csv\"):\n",
        "    files.download(file_path)\n",
        "\n",
        "# Download top_customers\n",
        "for file_path in glob.glob(\"top_customers.csv/part-00000-*.csv\"):\n",
        "    files.download(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "yb3B4DFFx7rs",
        "outputId": "0f2f7f7b-f3ba-4afd-a872-c0704ba69a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0e555f1e-1050-4c40-82d4-5a563569f165\", \"part-00000-0bfad0c6-5637-4f42-b237-c7256e7ac2ce-c000.csv\", 616)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_544e28be-226a-4bd7-9258-51c4c96153dc\", \"part-00000-2763435e-c417-4b0d-acd4-8aeab4701fb3-c000.csv\", 641)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}